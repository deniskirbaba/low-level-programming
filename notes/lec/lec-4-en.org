#+INCLUDE: "common/org-header.org"
#+LANGUAGE: en
#+TITLE: Chapter 4. Modularity and abstraction

# <
* Modularity and abstraction
# >

* References
  :PROPERTIES:
  :UNNUMBERED: notoc
  :END:

  - "Principles of Computer System Design: an Introduction":
    - Chapter 1, sections "1.4 Computer systems are the same but different", "1.5 Coping with complexity II"
#     - Chapter 4, sections "4.1 Client/Service Organization", "4.2. Communication between client and service"
  - "Low-level programming": Chapters 2,  3
#  - Joel Spolsky, [[https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/]["The Law of Leaky Abstractions"]].
  - [[https://tldp.org/LDP/lki/lki-2.html][Processes in Linux]] (The Linux Documentation project)
  - Intel® 64 and IA-32 Architectures Software Developer’s Manual. Volume 2B: Instruction Set Reference, N-Z.
    Instructions =prefetch0/1/2=.
    -----
    # < 
* Recap
  :PROPERTIES:
  :UNNUMBERED: notoc
  :END:

  - RAM machine and complexity analysis
  - Assembly language for Intel 64 and Linux:
    - registers, system calls, program structure, file output examples, conditional jumps
  - Encoding finite state machines in assembly

  -----

  # >
  
  # [
In this part we will discuss the following questions:
  # ]
  
  - Why did computers become so complex?
  - Software and hardware becoming more complex
  - Modularity and abstraction in software and hardware
  - Calling conventions.
  - How to make complex systems more robust?
  - How to enforce modularity and why it is important for multitasking?
  - Leaking abstractions, or why is assembly useful for Web-programmers.

  # [
  
  Почему компьютеры стали делать такими сложными? Как развитие компьютерных систем стало делом не просто одной корпорации, но многих и многих компаний, комитетов, исследовательских организаций?

  Создавать такие  системы тоже сложно. Пусть мы программируем, а не создаём аппаратуру сами, но даже /маленькие/ программы встраиваются в большую программно-аппаратную систему и начинают взаимодействовать с разными её частями. А в индустрии не редкость программы на миллионы инструкций. Так как же проектировать и развивать систему, состоящую из миллиардов движущихся частей?

  Если сложность системы с помощью различных трюков и смекалки не понижать, то достаточно скоро система становится неподъёмной для разработки и поддержки. Тогда её разработчики почти наверняка даже не смогут доделать её до конца. Какими путями можно снизить сложность?

  Один трюк мы уже увидели: в программировании это использование более подходящей для решения задачи модели вычислений. Например, если легко выразить систему как конечный автомат, сделайте это, а затем по надёжному, универсальному и простому алгоритму закодируйте систему на нужном языке. Тогда часть сложности уходит в трансляцию между моделями вычислений.
  
  Мы плотнее познакомимся с модульностью и абстракцией, увидим, как программа делится на части-модули на разных уровнях детализации, и устройство модулей скрывается от остальной системы. Если вы будете чаще думать про модульность ваших программ, вы чаще будете писать код с хорошей архитектурой. В ней сложность будет постоянно умело прятаться за абстракциями.

  Это настолько мощный подход к построению систем, что может сложиться впечатление, что абстракция скрывает от нас сложность модулей полностью, поэтому мы можем вечно жить в мире высоких уровней системы --- например, счастливо писать на высокоуровневых языках, ведь они нас отгородят от проблем внутри скрытых частей системы. На деле же абстракции почти всегда несовершенны и не скрывают сложность полностью, мы продемонстрируем несколько примеров. 

  Напоминаем, что в этом курсе мы не затрагиваем психологический, экономический аспекты истории развития компьютеров, которые, безусловно, важны для целостного понимания IT. Мы концентрируемся на столкновении растущей сложности систем с ограниченностью когнитивных ресурсов человека.

  # ]
  -----

* Why computer systems are becoming complex?

  
  Computer systems become complex to:

  - Solve problems faster.
  - Solve more problems.
  - Interact with complex peripherals

    # <
    - From a panel with lamps to a printer
    # >
    
    # [
    
    Мы представили компьютер как систему из процессора, памяти и транспорта между ними. Затем к этому добавились хранилище, регистры, прерывания. Эту схему можно усложнять достаточно долго, но даже после добавления множества блоков процессора, кэшей, шин, контроллеров, она будет бесконечно проще, чем реальный компьютер, в котором один лишь процессор содержит миллиарды транзисторов.

    Почему компьютеры так сложны? Усложнение компьютеров позволяет им решать более сложные задачи. Во времена полётов на Луну от компьютера требовалось немногим более, чем решение математических уравнений, но вскоре компьютеры стали объединяться в масштабные сети, использоваться для обработки всё больших массивов данных, а также взаимодействовать с другими устройствами. Когда-то менять содержимое памяти можно было буквально руками, вставляя стержни в ячейки и таким образом устанавливая биты; однако этот подход налагает совершенно неразумные ограничения на сложность программ, которые можно таким образом закодировать. Если мы хотим просто распечатать результаты работы программы на бумаге, нам уже нужно контролировать не панель с лампочками, а устройство с движущейся бумагой и какой-то печатающей составляющей, например, матрицей. Это гораздо более сложное устройство, которым непросто управлять. Но кроме того оно ещё и медленное, поэтому компьютер может успеть сделать множество полезных вычислений пока принтер в сравнении с ЦПУ еле шевелится. Чтобы переключаться между управлением принтером и другими задачами, компьютер тоже нужно усложнять...
    
    Итак, компьютеры становятся всё сложнее, чтобы решать задачи быстрее, чтобы все их компоненты использовались по максимуму, чтобы решать больше разных типов задач и взаимодействовать с другими, всё более сложными устройствами.
    
    # ]

  -----  
* Hardware & software
  # <
  - Computer systems = hardware + software
  # > 
  # [
  Когда-то никакие компьютеры не имели программной части. В первых компьютерах только сами схемы определяли, что за работа будет совершена. Инженеры быстро поняли, что менять такие системы и исправлять в них ошибки невероятно сложно, а ошибки появляются постоянно, поэтому стали делать их реконфигурируемыми. Софт стал той самой конфигурацией, которую можно менять. В фон Неймане и родственных архитектурах уже есть прошивка, софт, который управляет аппаратурой. Почти все современные компьютеры как вычислительные системы состоят из софта и аппаратуры.
  # ]

  # < 
  - Their interaction is making computer useful, they should be studied together.
  # >

  # <
  - Difference: software is not limited by physics.
  # >
  # [
  Наличие изменяемой памяти не означает наличие софта. Память может выступать исключительно в роли хранилища данных, например, в компьютерах есть /кэш данных/, аппаратная реализация памяти, в которой инструкций не бывает. Существуют и такие компьютеры в которых вся логика поведения определяется схемами, а память выступает только как хранилище данных.

  Софт управляет компьютерной системой и является её функциональным компонентом. Стоит помнить, что сами по себе инструкции без исполняющей её аппаратуры ничего не значат. Задачи, возложенные на компьютеры, решаются в танце, где ведущим выступает софт, а его партнёром --- аппаратура.

  Усложнение компьютеров затрагивает и аппаратную, и программную часть.
  # ]
  
  -----
  
** Complexity of hardware

   # <
   It is too hard to develop the whole hardware system.
   Divide and conquer: 
   - Describe overall architecture.
   - Describe interfaces between modules.

   Each organization develops one module.

   - Marketing: everyone wants to develop the fastest components
   - Sometimes can be sped up, but it is too expensive.
     - Registers are faster but take space on CPU.

   - Physics: energy efficiency, undesirable effects on high frequencies etc.
       
   Result: some parts of computer are very fast, others can not keep up.

   # >
   # [

   Начнём со сложности аппаратуры. Почему нельзя сделать быструю память и быстрый процессор, оставив архитектуру системы такой же?

   Оказалось, что даже сделать просто компьютер с архитектурой фон Неймана целиком очень сложно. Отметим, что в то время не было компьютерного инструментария для того, чтобы, например, проектировать на компьютерах новые процессоры. Компаниям пришлось договариваться о стандартизации архитектуры, её высокоуровневом описании, а также об описании интерфейсов всех модулей, из которых она состоит. Заметьте, что мы говорим не о внутреннем устройстве модулей, а об их интерфейсах: сами модули внутри очень уж сложные, а вот их интерфейсы описать возможно.
   
   Затем каждая компания стала на чём-то специализироваться, и они перестали думать о системах целиком. Возникла гонка, где каждый старался из соображений маркетинга сделать свою часть самой производительной и показать себя в более выгодном свете, нежели конкуренты. Капитализм!

   Нет смысла делать сверхбыстрый процессор, который большую часть времени ожидает данные из медленной памяти. Когда всю систему делает одна команда разработчиков, инженеры не стремятся достичь максимальной производительности отдельных компонентов если система не сможет этим воспользоваться. А когда каждый компонент стала делать отдельная команда, так и случилось: части компьютеров стали слишком сильно различаться в производительности.

   Как поступают системные инженеры в такой ситуации? Вспомним пример с каньоном и поездом, который по нему едет. Чтобы максимизировать использование железной дороги нам пришлось усложнить систему, добавив стрелки, дополнительный путь и какую-то систему контроля, которая не позволяет поездам столкнуться. Так и с компьютерами: их пришлось снова усложнять чтобы более эффективно использовать, например, очень эффективный процессор.

   # ]
   -----

   # [
   #+INCLUDE: "common/before-image.org"
   #+attr_latex: :width 0.60\textwidth
   #+attr_html: :width 60%
   {{{if-latex-else([[./img/train.svg]],)}}}
   #+INCLUDE: "common/after-image.org"
   # ]


   # <
   #+BEGIN_EXPORT md
   <p align='center'> <img width='30%'  src='./img/train.svg' /> </p>
   #+END_EXPORT
   # >
   
   -----
   
*** Maximizing resource usage
    # <

    In systems we try to maximize the resource usage: CPU should not idle.

    A mechanism to provide the resource to different parts of the system makes it more complex.
    # >
  #+CAPTION: Архитектура фон Неймана с дополнениями

  
# [
#+INCLUDE: "common/before-image.org"
#+attr_latex: :width 0.60\textwidth
#+attr_html: :width 60%
{{{if-latex-else([[./img/von-neumann-complete.svg]],)}}}
#+INCLUDE: "common/after-image.org"
# ]


# <
#+BEGIN_EXPORT md
<p align='center'> <img width='90%'  src='./img/von-neumann-complete.svg' /> </p>
#+END_EXPORT
# >
    # [

   Процессор оказалось разогнать легче, чем память, поэтому чтобы использовать процессор более эффективно, без простоев, в систему добавили промежуточные уровни памяти:  регистры и несколько уровней кэшей. Помимо этого возникли и другие механизмы, мы упомянем три из них: предсказание ветвлений, предзагрузка данных в кэш и конвейер. Эти приёмы повышения производительности вы сможете найти и в программных системах, не только в аппаратуре.
    # ]

    -----
*** Branch prediction
    # <
    When branching occurs, guess the branch in advance.

    If the prediction fails, we have to rollback (but CPU rarely fails).
    # >
     
    # [
    Рассмотрим такой псевдокод:
    # ]
    #+BEGIN_SRC asm
      ; rax = rbx + 3 * rcx
      mov rax, rbx
      add rax, rcx
      add rcx, rcx
      add rax, rcx
      ; if (rax < 5) goto yes
      cmp rax, 5
      jb yes
      ; first branch: rax < 5
      ...
      yes: ; second branch: rax ≥  5
    #+END_SRC

    # [
    Сначала программа считает значение регистра =rax= по формуле =rax = rbx + 3 * rcx=. Если =rax < 5=, то программа переходит с помощью инструкции =jb= на метку =yes=, иначе она продолжает выполнение. То есть, в зависимости от результата будет выполнена одна из двух веток кода.
    Пока процессор не подсчитал точное значение =rax=, он не знает, какая ветка будет выполнена. Но он может попробовать угадать ветку и начать выполнять её заранее. Если процессор угадал, то всё хорошо. Если не угадал --- придётся откатить все эффекты инструкций в неправильной ветке назад и начать выполнять правильную ветку.
    
    Процессор настолько быстрее всего остального, что даже если он не угадывает, это не очень замедляет вычисления. А угадывает он чаще, за счёт чего в среднем производительность повышается.

    Есть несколько распространённых стратегий для предсказаний веток: статические (не учитывающие то, как программа выполняется, и всегда предсказывающие одинаково) и динамические (с каким-то анализом истории выполнения программы). 
    # ]

    -----
    
*** Prefetching values to cache
    # <
    Guess where the memory reads will occur, load to cache in advance.
    # >
    # [
    Компьютеры умеют передавать данные из основной памяти в кэш не занимая вычислительный ресурс процессора. Если для программы в ближайшем будущем понадобятся данные с определённых адресов, имеет смысл заранее их закэшировать. Пока процессор что-то считает, можно инициировать процесс записи данных из памяти в кэш, а когда данные понадобятся, они будут уже в кэше.

    Иногда процессор может сам догадаться, что определённые данные ему скоро понадобятся. Например, если мы просматриваем длинный массив, процессор предполагает, что мы и дальше будем двигаться по массиву. При чтении из памяти длинных последовательностей данных процессор будет заранее подгружать данные в кэш.

    В случаях нетривиальных паттернов доступа к памяти процессор уже не сможет догадаться, что ему кэшировать. Существуют инструкции, подсказывающие процессору, что указанные данные имеет смысл закэшировать. Например, инструкции =prefetch0/1/2= в Intel® 64 and IA-32 Architectures Software Developer’s Manual. Volume 2B.
    # ]

    -----
*** Pipeline
     
    # <
    The execution of an instruction is split to stages. Different stages on different parts of processor.

    When we reach second stage of execution we can start executing next instruction simultaneously.

    This approach can be used in many distributed systems by giving subproblems to independent nodes.

    # >
     
    # [

    Процессор внутри состоит из множества блоков; инструкция при исполнении задействует некоторые из этих блоков. Причём на разных стадиях своего выполнения инструкции нужны разные блоки.

    Представим простейшую ситуацию: есть два блока процессора, каждая инструкция по очереди задействует эти блоки. Представим также две последовательные инструкции. Тогда пока первая инструкция не выполнится, вторая будет ждать доступа к первому блоку, хотя первой инструкции он может уже не быть нужен.
     
    Конвейеризация разделяет операцию на несколько подопераций и распределяет их по разным частям системы, чтобы они могли работать параллельно.

    Такой же трюк можно применять в распределённых программных системах. К примеру, в распределённой базе данных можно параллельно выполнять запросы, задействующие разные ноды в кластере.
    
    # ]
     
    -----

** Complexity of software

   Software part of systems is much more complex than hardware.
  
   # [
   Это может показаться абсурдным, ведь программы мы пишем постоянно.  А процессор сделать гораздо сложнее, чем написать небольшое приложение на Java. Однако даже простейший =Hello, world!= встраивается в огромную программно-аппаратную систему, включающую операционную систему, драйвера, другие запущенные приложения и т.д.

   Вот почему программная часть систем получается сложнее:
   # ]
   
   - Physical laws limit hardware.
     
   # [
   Если на создание аппаратуры налагают ограничения технологический процесс и фундаментальные физические законы (например, появление паразитных токов на высоких частотах), то сложность программ мы можем наращивать почти неограничено.
   # ]
   - Easy to compose.

   # [
     Не составляет труда быстро составить систему из нескольких огромных систем, например, связать Word и СУБД с помощью небольшого скрипта. Если получившаяся система неправильно работает, ошибка может быть в Word, в СУБД или в связке (макросах).
   
   Именно потому, что программы писать так сложно, а также потому, что мы в основном этим и занимаемся, оставшуюся часть мы посвятим тому, как бороться со сложностью программ с помощью модульности и абстракции.
   
   # ]

   -----

* Modularity and abstraction
  
  System architecture requires: 

  - dividing the system on modules.
  - abstracting modules.

  # [
В этом разделе мы поговорим про модульность и абстракцию именно в программах. Это знание пригодится вам вне зависимости от технологий и языков программирования, которые вы используете.
  # ]
  
  -----
** Program in computer system

  # [
  Напомним отношение между программами и вычислительными системами.
  # ]
  In any system /systemic properties/ are a result of interaction of the parts of the system.
   
  # <
  - Running program --- system, includes hardware.
  - Source code is not a system, it is not active.
  # >

  # [
  Исходный код программы после трансляции в машинные инструкции и запуска приложения "встраивается" в вычислительную систему.

  Когда программа написана в одном большом файле, она добавляет в вычислительную систему один большой модуль, который сложно изучать и отлаживать. Если же разделить исходный код на части, то запуск программы можно мысленно воспринимать как внесение в систему нескольких модулей поменьше.

  Одна из важных причин разделения системы на модули в том, что если сделать это удачно, то локализовывать ошибки с точностью до модуля становится достаточно просто. Если модуль при этом небольшой, то легче детально его изучить чтобы найти конкретное место в программе, которое нужно исправить.
   
  # ]
  -----

** Modularity: compile time & run time

   # [
   TODO rewrite
   Redundancy
   
   Хотя исходный код программы не является системой, но в нём тоже можно выделить модули, которые потом проникнут в систему. Разбивка кода на модули разной степени гранулярности в каком-то виде сохраняется при компиляции и запуске программы.

   Важно понимать: хотя и работающая программа (система) и исходный код состоят из модулей, программа и исходный код это разные сущности. Поэтому и разбиения эти разные, и модули разные. Процессор, части операционной системы, драйвера, внешние устройства являются частями вычислительной системы, но не имеют отношения к исходному коду программы. Появятся при запуске и чисто софтовые модули, например, экземпляры процедур (об этом позднее).
   
   # ]

   # <
   - System (running program) contains modules.
   - Source code has modules. 
   - But: structural decomposition of different entities and modules are different too.

   # >
   
   # [
   После разбиения на файлы можно и нужно разбивать программу на ещё более мелкие сущности. В зависимости от языка, это могут быть классы, функции, методы, пространства имён и многое другое. С точки зрения систем это будут тоже модули, только более низкого уровня.
   # ]


   # < 
   Two aspects of programs: compile time & run time.
   # >
   
   # [
   Таким образом проявляются два аспекта многих из дисциплин, связанных с программированием:

   1. /Compile time/: как программы проектируются.
   2. /Run time/: как программы выполняются.

   
   # ]
   -----

** Abstraction: compile time & run time

   # [
   Если модульность существует и в compile time, и в run time, верно ли, что абстрагировать можно не только модули системы, но и модули в исходном коде? Ответ --- да, и для статических, compile-time модулей, мы можем описывать их поведение абстрагируясь от внутреннего устройства и ненужных деталей.

   Многие языки программирования предоставляют инструменты для абстракции таких модулей. Например, интерфейс функций, как модулей системы --- набор аргументов и возвращаемое значение. Во многих случаях этой информации достаточно, чтобы пользоваться функцией, ничего не зная про её внутреннее устройство. Классы в Java имеют публичные и приватные поля и методы; при этом публичные поля и методы образуют интерфейс для экземпляра класса, а о приватных знать пользователю не только не нужно, но и, практически, запрещено языком.
   # ]

   # < 
   - Modules can be complex.
   - Behavior is more important than internal structure.
   - Behavior is usually easier to describe. 

   /Abstration/ --- describing behavior and interface instead of internal structure + hiding structure.

   /Interface/ is a way of interacting with module. 
   
   It is possible to abstract modules in source code too.

   # > 
   ----- 

* Modularity and abstraction in compile time

  # [

  Для начала рассмотрим структуру кода на ассемблере, как одном из наиболее безыскусных языков. Для каждого уровня декомпозиции мы укажем средства абстрагирования модулей, если они существуют.
  
  # ]
  
** Structure of source code
  
   For assembly:
 
   - Source code (project)
     - File
       - Section
         - Routines
       - Sections
         - Variables
     - File
       - Section

         ...

   -----

*** File

    # [

    Вообще файл с исходным кодом программы это всего лишь именованный набор данных, то есть структурная единица хранения данных. Однако в ассемблерных файлах и в языке С на файл оказалась возложена и другая функция: он стал структурной единицей для самой программы.

    В общем случае файл не обязательно является структурной единицей для программы:

    - в Java связь между файлом-хранилищем кода и файлом-модулем системы ослаблена: структурной единицей программы является описание класса, но наложено условие, что в каждом файле может быть не более одного класса, помеченного =public=.
    - в C# файлы вообще никак не связаны со структурой программы; разве что нельзя дробить тело метода на несколько файлов (но определение класса --- можно).
    
    Язык Smalltalk обходится без файлов вообще --- там программа описывается как слепок состояния виртуальной машины, а структурной единицей программы является описание класса.

    Если файл --- это модуль, то чтобы реализовать абстракцию у него должен быть интерфейс, видимый другим файлам, и скрытая, абстрагированная часть.
    
    Точками взаимодействия с файлом являются метки. Обычные метки не видны извне файла, а метки для внешнего использования отдельно помечаются директивой =global=.
    
    # ]

    # <
    - Labels describe all points of interaction.
    - Labels marked as ~global~ describe interface.
    - ~extern~ connects to the interfaces of other modules.
    # >

    -----
 
    #+BEGIN_SRC asm
; This variable is available to other files
global x
section .data 
    x: db "Hello!"
    #+END_SRC

    # [
    На другой стороне чтобы подсоединиться к коду из внешнего файла используется директива =extern=.
    # ]

    #+BEGIN_SRC asm
; Using variable from external file
extern x

section .text
  mov rax, x
    #+END_SRC


    # [
    Таким образом, директивы =global= и =extern= --- средства абстракции файлов-модулей. Директива =global= служит для описания интерфейса к файлу; абстракция заключается в том, что все остальные метки в файле скрыты от внешнего мира.
    # ]
      
    -----


*** Sections

    # [
    В файле находятся секции, которые никак не отражаются в структуре программы, кроме как собиранием в отдельные кучки всех глобальных данных (в =.data=), отдельно неизменяемых данных (в =.rodata=), всего кода (в =.text=) и т.д.
    # ]
    
    # <
    Store code and data structurally.

    - Labels describe interface (where variables or functions start).
    - ... but any address in a section is reachable.
      
    # >


    # [
    Внутри секции можно обращаться к любым адресам; в этом плане метки лишь выделяют некоторые адреса как "интересные" для программиста, потому что именно с этих адресов начинаются данные, функции, или на эти адреса нужно переходить.
    # ]
    -----
   

*** Functions, subroutines

    # <
    - Function --- structural unit of code.
# >
    # [
    Функции также являются структурными единицами кода на языках высокого уровня. Мы привыкли думать о функциях как о минимальной единице построения кода.

    Функции упрощают код: их можно вызвать с аргументами, они возвращают значение и применяют побочные эффекты, такие, как ввод-вывод из файлов. Это показывает, что, во-первых, функции это модули, во-вторых, они абстрагируют свою реализацию за простым интерфейсом. Интерфейс функции это её вызов с аргументами, и получение возвращаемого значения.

    
    
    # ]

    # [
    #+INCLUDE: "common/before-image.org"
    #+attr_latex: :width 0.50\textwidth
    #+attr_html: :width 50%
    {{{if-latex-else([[./img/function.svg]],)}}}
    #+INCLUDE: "common/after-image.org"
    # ]


    # <
    #+BEGIN_EXPORT md
    <p align='center'> <img width='60%'  src='./img/function.svg' /> </p>
    #+END_EXPORT
    # >
    
 # < 
    - In assembly functions become /subroutines/.
    - Subroutines have no defined borders.
    - Calling subroutines --- no control over arguments.
    # >
    -----
  # [ 
   Чем меньше у функции сайд-эффектов, тем проще её подменять, анализировать, писать, тестировать. Поэтому в своих программах на любом языке сводите сайд-эффекты к минимуму. Это означает отказ от глобальных переменных и разделение логики и ввода-вывода: если функция что-то считает, она не должна выводить это, а должна передать как результат другой функции, которая уже и будет заниматься вводом-выводом. Старайтесь по возможности придерживаться правила: функция принимает всё, что ей нужно для работы, через аргументы, и все результаты работы возвращает через возвращаемое значение.
   
    На уровне ассемблера функции часто называют /подпрограммами/. Мы будем использовать этот термин когда необходимо подчеркнуть различия функций в языках высокого уровня и на уровне ассемблера.

    Отличия функций и подпрограмм: 

    1. Границы функций определены их телами: в Java, например, тело метода ограничено фигурными скобками.
    
          #+BEGIN_SRC java
          public static void main(String[] args)
          { // начало функции

          } // конец функции
          #+END_SRC

          Границы подпрограмм могут быть чётко не определены. Например, подпрограмма может иметь несколько точек входа, то есть можно начинать её исполнять с начала, а можно с середины. Где в таком случае провести её границы?
          Например, в этой программе мы можем вызвать функцию =print_hello= с середины, где стоит метка =print_string=; в таком случае можно передать в качестве аргумента произвольную строку для вывода.

          #+INCLUDE: "./listings/coroutine.asm" src asm
    # ]
    # < 
     Borders of subroutines are not well defined. 
    #+INCLUDE: "./listings/coroutine.asm" src asm :lines "4-23"
    # >
    # [
    2.  Подпрограммы оперируют в глобальном контексте.
         У функций есть локальные переменные и аргументы, которые являются изолированной частью состояния программы.
         
         Подпрограммы же оперируют с регистрами, а изменения регистров видны всем другим функциям. Неизолированность подпрограмм друг от друга нельзя полностью обойти, но часто чтобы зарезервировать кусочек памяти для локальных данных подпрограммы используют стек. Чуть далее узнаем, как это происходит.
    # ]
    -----
    # [
    3. За вызовом подпрограмм нет никакого контроля. Если функция в Java принимает три аргумента, а вы передаёте ей два, код  с неправильным вызовом функции не скомпилируется. А подпрограммы можно запустить в любом контексте, вне зависимости от того, положили ли вы в регистры нужные аргументы и правильных ли они типов.

   
    # ]
    # <
    No argument control when calling subroutines. 
    
    # >
    #+BEGIN_SRC  c 
      int sum(int a, int b) {
        return a + b;
      }
      ...
      rcx <- sum( 42 ) // error: missing argument
    #+END_SRC

    #+BEGIN_SRC asm
        ; rdi = a, rsi = b
        sum: 
              mov rax, rdi
              add rax, rsi
              ret
      
        ...
        mov rdi, 42   
        call sum         ; Second argument taken from rsi anyway
        mov rcx, rax     ; Most probably a garbage value
    #+END_SRC
   
    # [
    Из-за того, что контроля за вызовом подпрограмм нет, приходится договариваться о том, как делать это единообразно. Невозможно устроить взаимодействие между разными функциями без согласования порядка аргументов, набора регистров, в которых они передаются, механизма передачи возвращаемого значения. Как мы увидим далее, эти /соглашения вызова/ играют важную роль в построении вычислительных систем.
   
   Теперь перейдём к выполнению программы и проследим, как части исходного кода программы разной степени гранулярности становятся модулями в вычислительной системе.
   # ]
   -----
     
* Modularity and abstraction in runtime

  # [

  Формат файла, структурирующий код, зависит от операционной системы. В Linux самым распространённым является формат ELF, о котором мы в деталях поговорим позже. ELF-файлы содержат метаданные, такие, как разметку на секции, названия меток и т.д.

  # ]
 
  # <
  After being translated to machine code the file is transformed into a structured format and can be loaded by /loader/.
  # >

  # [

  Структура работающей программы во многом повторяет структуру исходного кода программы на ассемблере. Это одна из причин, по которой нам интересно изучение ассемблера.
  
  # ]
  -----

** Structure of a running program

   # [
   Сразу оговоримся, что мы для конкретики рассматриваем то, устроена работающая программа, запущенная под Linux или с использованием похожей ОС и архитектуры Intel. В большинстве распространённых контекстов всё сказанное останется верным, детали могут различаться. Однако если вы напишете свою ОС или сделаете платформу для запуска приложений, структура работающей программы у вас может быть совершенно непохожей.
  
   На высоких уровнях иерархии организация вычислительной системы зависит от приложения, которое выполняет пользователь. Мы начнём рассматривать структуру программы начиная с процессов.
   # ]
   
   - *Process* (container for threads and resources: file descriptors etc.)

     # <
     From all source code and libraries.
     # >

   # [
   Каждый процесс содержит ресурсы, необходимые для функционирования программы: виртуальная память, дескрипторы открытых файлов, обработчики сигналов, информация про /рабочую директорию/, из которой был запущен процесс, и т.д.

   В образе процесса можно найти не только продукт трансляции исходного кода программы, но и библиотеки, в том числе динамические.
   # ]
   
   - New entity: *thread*. 

   # [
   В языках, основанных на фон Неймановской модели вычислений или её наследниках, мы не описываем потоки явно.  При написании программы у нас есть иллюзия того, что она выполняется последовательно, в один поток. В реальности некоторые системные вызовы служат для создания новых потоков и запускают их параллельно.

   При выполнении программы процесс служит контейнером для потоков. Потоки также выступают единицей планирования, т.е. планировщик процессов на самом деле предоставляет процессор потокам, а не процессам.

   # ]

   - Regions of address space (containers for sections).
     # <
     ~.text~ and ~.data~ are loaded in different areas of in memory.
     # >

-----
   # <
  #+CAPTION: Загрузка файла в память
  [[./img/loading.svg]]
  # >
   
-----
   # [
   У каждого процесса есть своё адресное пространство, оно общее для его потоков. При компиляции и компоновке программы все машинные инструкции собираются вместе и формируют одну большую секцию кода, то же самое происходит и с глобальными данными. При загрузке программы в память эти секции попадают в разные части виртуальной памяти.

   По отношению к секциям можно говорить о модульности, но не об абстракции. Можно обращаться ко всему, что загружено в память. Есть механизмы защиты от, например, перезаписи кода, которые предоставляются виртуальной памятью, но это не скрывает устройство секций кода или данных от других секций.
   
  #+CAPTION: Загрузка файла в память
  [[./img/loading.svg]]
  
   На самом низком уровне мы строим программу из подпрограмм. В работающем процессе к ним применимы все те же соображения, что и к подпрограммам в ассемблерном коде: они являются модулями, их интерфейс --- вызов и возврат из них.

   
   # ]
    

   - *Function instances* (running functions and their local data).

   # <
   Stack allows to run several instances of the same function independently. 
   # >
   
   # [
   Во время выполнения добавляется ещё один тип сущности, которого нет в исходном коде: это экземпляры функций. При запуске функции она некоторое время живёт в программе, и в это время ей нужна память под её /локальные переменные/. А что если функция уже запущена, но нам нужно запустить её ещё раз с другими аргументами? Это не должно затронуть работу уже запущенной функции.

   Чтобы изолировать локальные переменные запущенных одновременно функций используют стек. Каждый раз, когда мы запускаем подпрограмму, в стек помещается её адрес возврата, а затем можно разместить её локальные переменные.
   
   Иллюстрация показывает результат выполнения инструкции =call f=, которую можно представить как пару действий: =push rip= и =jmp f=.
   
   # ]

  -----


   # <
  Return address in stack.
   # >
   #+begin_export latex
    \svgsetup{inkscapelatex=false}
   #+end_export
   #+CAPTION: Адрес возврата в стеке.
   [[./img/ret-addr.svg]] 
   
   #+begin_export latex
    \svgsetup{inkscapelatex=true}
   #+end_export

   # [

   Затем мы выделяем 24 байта под локальные переменные, отодвигая  =rsp=  к младшим адресам с помощью =sub rsp, 24=:

   # ]
   -----

   # <
   Local variables in stack. 
   # >
   
   #+begin_export latex
    \svgsetup{inkscapelatex=false}
   #+end_export
   #+CAPTION: Локальные переменные в стеке.
   [[./img/locals.svg]]

   #+begin_export latex
    \svgsetup{inkscapelatex=true}
   #+end_export

   # [
 
   Использование стека для организации вызовов функций и хранения локальных переменных позволяет:

   - запускать функцию многократно (например, =f= запускает =g=, которая запускает =f= снова);
   - устраивать рекурсию;
   - запускать функцию в нескольких потоках одновременно.

   # ]
   -----
* Calling conventions

-----

* System view 
  # [
  Functions are modules of the system and their interface has to provide two features:
  # ]
  # <
  - Functions are modules.
  - Interface:
    # >
    - call from anywhere;
    - return values. 

  # [
  If we descend to the assembly level, there are instructions =call= and =ret= for launching subroutines and returning from them.
  But there are no instructions that would allow us to describe the full interface like the number of arguments or their types.

  It seems that choosing how to pass arguments becomes the responsibility of an individual programmer.
  # ]

  -----

  # <
  Assembly is limited to: =call=, =ret=, no support for argument passing.

  The rest is for us to figure out.
  # >


 #+BEGIN_SRC asm
int sum(int a, int b) {
  return a + b;
}

...

rcx <- sum( 42, 44 )
 #+END_SRC

 -----

 ... translates into:

 #+BEGIN_SRC asm
; rdi = a, rsi = b
sum: 
      mov rax, rdi
      add rax, rsi
      ret

...
mov rdi, 42
mov rsi, 44
call sum
mov rcx, rax
 #+END_SRC

 -----

* Calling conventions

   # <
   - to call all functions in the same way.
   - to reuse the code.
   # >
   
   # [
   When we control all the code being executed on the computer, e.g. if we are writing the operating system and all applications, we can chose:

   - which registers will hold arguments;
   - which will hold return values;

   Or maybe we should use stack to pass arguments?
   However in order to interact with programs written by others we have to develop a convention describing how programs should call each other.
   Then everyone should adhere to this convention.

   The calling conventions are motivated by two reasons:
   
   1) Programmers want to reuse code written by others, not just themselves.
   2) If all functions are being called differently, it introduces irregularities in the system making it more complex, which is the opposite of what we want to have.
      
   The most popular conventions on Intel 64 are:
   # ]
 # <
   Most popular conventions on Intel 64:
# >
   1. System V AMD64 ABI (Linux, FreeBSD, MacOS)

      Described "System V Application Binary Interface".

   2. Microsoft x64 (Windows, UEFI)
# <
   Few differences, we study a simplified version of System V.
   # >

  # [
  We will focus only on the first convention --- System V.
   # ]

   -----
    
**  System V AMD64 ABI (first approximation)

   # [
System V AMD64 ABI describes the function calling sequence as follows:

   1. First six arguments in registers

        =rdi=  =rsi= =rdx=
        =rcx= =r8= =r9=

      It is enough to memorize the first three. 
       
   2. Other arguments are passed on stack in reverse order.

      For example, if we call =f(a,b,c,d,e,x,y,z)= the argument =z= will be placed at the top of the stack, followed by =y=.
      If all arguments were passed on stack, the subroutine calls would have been much slower.

   3. Return value is in =rax=; a second return value may be returned in =rdx=.

   # ]
   # <
   - first six arguments :: (memorize three):
     =rdi=  =rsi= =rdx=
     =rcx= =r8= =r9=

   - other arguments :: stack, reverse order.
     Registers are faster than stack.
   - return value ::  =rax=, additional in =rdx=.

   # >

   -----

** System calls
   
   System V ABI has different conventions for system calls and subroutines.
   
   # [
   System calls accept arguments in different registers: the fourth argument is accepted in =rcx= instead of =r10=.
   It has been done because the =syscall= instruction uses  =rcx= to store the current value of =rip=, and =r11= to store =rflags=.
   These registers are not preserved when the system call handler starts execution so we need to store them automatically to be able to preserve them.
   
   # ]

   - Arguments in registers:
     - =rdi= =rsi= =rdx=
     - =r10= instead of =rcx= (=syscall= uses =rcx= )
     - =r8= =r9=
   # <
   - *No more than 6 arguments*.
     # >
     
   # [
   Note that it is possible to implement system calls using any instruction that leads to an interrupt, not necessary a dedicated =syscall= instruction.
   Different operating systems use different ways of invoking system calls.
   # ]

   -----


** Second approximation

# [
   Let us study the following example first.
# ]

   #+BEGIN_SRC asm
; rdi = address of string
string_length:
    xor rax, rax
    .counter: cmp byte [rdi+rax], 0
                  je .end
                  inc rax
                  jmp .counter
        .end:  ret
; rdi = address of string
print_string:
    call string_length
    mov rdx, rax
    mov rax, 1
    mov rsi, rdi
    mov rdi, 1
    syscall           ; calling `write` 
    ret
   #+END_SRC

   Is there an error here?
   
   -----
   Suppose our colleagues have rewritten =string_length= as follows:
    
   #+BEGIN_SRC asm
       ; rdi = address of string
       string_length:
           mov rax, rdi
           .counter:
               cmp byte [rdi], 0
               je .end
               inc rdi
               jmp .counter
           .end:
           sub rdi, rax
           mov rax, rdi
           ret
       ; rdi = address of string
       print_string:
           call string_length
           mov rdx, rax
           mov rax, 1
           mov rsi, rdi
           mov rdi, 1
           syscall           ; calling `write`
           ret
   #+END_SRC 

   # [
   The first version of =string_length= did not use =rdi=.
   The new version of =string_length= is still correct, but it uses =rdi=.
   Now when we call =string_length=, the value of =rdi= is changed.
   But for the caller, =print_string=, it is important  that the =rdi= got preserved!
   

   # ]
   -----

   # <
   #+BEGIN_SRC asm
string_length:                   ; old
  xor rax, rax
  .counter:
      cmp byte [rdi+rax], 0
      je .end
      inc rax
      jmp .counter
  .end:
      ret
string_length:                  ; new
    mov rax, rdi
    .counter:
        cmp byte [rdi], 0
        je .end
        inc rdi                      ; !!!!
        jmp .counter
    .end:
    sub rdi, rax
    mov rax, rdi
    ret
     
   #+END_SRC

   Replaced the implementation of a subroutine, the program crashes.

   Replaced the implementation of a module, the system crashes.

   # >

   # [
   This shows that the convention we are developing is not perfect.
   Programmers are not aware that in some contexts they should not use =rdi= (and really should not they?)
   It is not enough to describe which registers are used to pass arguments and to return values.
   Functions and subroutines are modules and we need to be able to:
   
   - develop them in isolation from the rest of the system and
   - replace one implementation with another.
      
# ]
   -----
     
   # <
Need to save registers (but which ones?)
   # >
     
   # [

   The problem that emerged when we changed =string_length= is that =rdi= was holding an address of a string before call.
   After the call to =string_length= this value was lost.
   To fix this problem we push =rdi= to stack before call and restore it afterwards:
   # ]

   
   #+BEGIN_SRC asm
       ; rdi = address of string
       string_length:
       ...
       ; rdi = address of string
       print_string:
           push rdi        ; !
           call string_length
           pop rdi         ; !
           mov rdx, rax
           mov rax, 1
           mov rsi, rdi    ; <---- need: rdi = address of string!
           mov rdi, 1
           syscall         
           ret
   #+END_SRC 

   -----

* Callee-saved and caller-saved registers
  # [

 In the last example we saved =rdi= because:

 1) it was precious to the caller (=print_string=), and
 2) the callee (=string_length=) can potentially change it.


 Is the callee able to change any register?
 In theory, yes.
 However, this requires us to always save all registers that hold precious data because they might be overwritten by function calls.

 To resolve the situation there are two extreme options:

 - Allow subroutines to modify any registers; then all precious registers have to saved by caller.
 - Forbid subroutines from modifying any registers; then all subroutines will have to preserve all registers.

  # ]

  # <
  Registers: callee-saved and caller-saved.

  # >
  # [
   Both approaches will lead to decreased performance because we will constantly save too many registers.
   Additionally, it does not make sense to restore registers that were used to pass arguments to subroutines.
   Because of this the calling conventions divide registers on two groups: caller-saved and callee-saved.

  # ]

** Callee-saved

   # [
   Some registers (/callee-saved/) have to be preserved.
   They can be used but when the subroutine terminates their values should be restored.
   # ]

   Saved by /callee/ (called procedure):

   - =rbp= and =rsp=, take part in the function calling sequence.
   - =rbx= , used in shared libraries.
   - =r12=, =r13=, ... =r15=, for convenience.

   -----
*** Caller-saved 
    # [
    It is allowed to use other registers (/caller-saved/) without restoring them.
    Only the ones that the caller needs have to be saved before =call=.
    # ]
   # <
    Saved by /caller/ (which calls). All other registers.

    You are free to use them in your programs.
# >
    -----
    # [
    To sum in up, a calling convention defines: 
    # ]
    # <
    Calling convention:
    # >
    - How to accept arguments (registers, stack...);
    - How to return values (registers, stack...)
    - Which registers will not change after call (callee-saved);
    - Which registers may be changed by a calll (caller-saved).

    # <
    Depends on OS, CPU, environment (think about language virtual machines).
     
    # >
    # [
    As we have seen with =string_length=, calling convention is not a restriction.
    You can easily violate it  and plant a time-bomb in your code which will only explode when you change another part of the code in the future.
    # ]

-----

* Abstraction and calling conventions

  # [
  From a systems point of view, functions are modules.
  They can be called, they can accept arguments and return values.

  Other actions related to the execution of a function are called its  /side-effects/.
  It usually includes the following:

  - working with files;
  - network;
  - writing to global variables;
  - input and output etc.
  
  # ]
# [
  #+INCLUDE: "common/before-image.org"
  #+attr_latex: :width 0.6\textwidth
  #+attr_html: :width 60%
  {{{if-latex-else([[./img/function.svg]],)}}}
  #+INCLUDE: "common/after-image.org"
  # ]


  # <
  #+BEGIN_EXPORT md
  <p align='center'> <img width='60%'  src='./img/function.svg' /> </p>
  #+END_EXPORT
  # >
  
  # <
  - Different implementations of modules conforming to the same interface should be *interchangeable* and *indistinguishable*.
  - Calling conventions help achieving interchangeability of functions with the same interface.
    # >

  # [

  Other properties of functions are hidden, abstracted away: we should not know how exactly the functions compute their results.
  - Different implementations conforming to the same interface should be interchangeable and indistinguishable.
  - Calling conventions help achieving interchangeability of functions with the same interface.

    Respecting calling conventions is necessary  to hide the details of execution of subroutines, for example, specific registers that they might change for their inner goals (like =string_lenght= was using =rdi=).
    Hiding details, in turn, allows to change them under the hood, easily replacing one implementation with another.

    Unfortunately, this is not a sufficient condition 
  # ]
  -----

* Leaking abstractions

  # [
  Абстракции помогают нам следующим образом:

  - Описывая модули через их поведение, а не структуру, упрощают их использование.
  - Скрывая часть описания модуля, облегчают изменение и подмену модулей, т.к. скрытые части модуля точно напрямую не взаимодействуют с внешним миром.

  В идеальном мире абстракция полностью скрывает от нас внутреннее устройство модуля и даёт ему более простое описание. В реальном мире это скорее редкость, и как правило поведение реального модуля не полностью укладывается в упрощённое, высокоуровневое описание.
  # ]

  # <
Network interaction looks like file I/O (but network does not guarantee data delivery).
  # >
  # [

  Рассмотрим ситуацию, когда мы посылаем по сети TCP-пакет. Протокол TCP /гарантирует/ доставку пакета, в отличие от, например, протокола UDP. Оба они действует поверх протокола IP, то есть TCP-пакеты упакованы внутрь IP-пакетов. Протокол IP не гарантирует доставку пакетов: потеря пакета считается нормальной ситуацией.

  Протокол TCP же будет пытаться отправить потерянный пакет снова и снова, и для отправки пакета будет использовать ненадёжный протокол IP.

  Однако никакое количество попыток пересылки пакета не приведут к его доставке если получатель выключил компьютер или перерезал сетевой кабель. В этом случае абстракция со свойствами гарантированной доставки, которую предоставляет TCP, не скрывает нас от деталей нижележащих слоёв системы, в которых пакеты не могут быть доставлены с гарантией.


  # ]

  Abstraction /leaks/ if it does not hide all the inner module structure.
    
  # [

  Другой пример связан с криптографией. Можно изучать время выполнения тех или иных действий модулем и таким образом получить информацию о его внутреннем устройстве, например, о том, на каких входных данных он работает медленнее. Это опасно с точки зрения безопасности, так как взломщики криптографических алгоритмов иногда могут таким образом открывать достаточно информации о ключах шифрования, чтобы их эффективно подбирать.
   
  Многие ошибки в системах обусловлены тем, что разработчики слишком полагались на высокоуровневое описание системы и не думали о более низких уровнях.
  
  Между тем часто случается, что удобные системы с гарантиями строятся поверх так называемых /best-effort систем/, как протокол TCP поверх IP. В best-effort системах происходит попытка удовлетворить запрос пользователя, но неуспех операций это штатная ситуация. Так же происходят чтения и записи из памяти и хранилища на самом низком уровне, коммуникация между компьютером и внешними устройствами и т.д. В программных системах встречаются ситуации, когда в силу несовершенства программы она иногда аварийно завершается; в этом случае в качестве временного решения используют принцип "запускать пока программа не доработает до конца". Временное решение, к несчастью, почти всегда становится постоянным.

  Поэтому даже если мы пользуемся высокоуровневыми абстракциями и инструментами, такими, как языки высокого уровня, нам всё равно нужно знать, что происходит под капотом на несколько уровней системы вниз.  Абстракции действительно упрощают нашу жизнь и позволяют нам писать программы более эффективно, но практически каждая из них в тех или иных условиях протечёт, и если вы не знаете, что она абстрагирует,
  # ]

  Abstractions spare us time building systems but do not spare time learning.

  # [
  Поэтому с каждым годом стать хорошим программистом всё тяжелее, потому что учиться приходится всё большему количеству технологий.

  Стоит отметить также, что /хорошие абстракции протекают меньше/. Старайтесь, чтобы в ваших собственных программах абстракции были хорошими.
  # ]

  -----

** Consequences of violating conventions
  
   # [
   Как мы говорили, функции абстрагируют часть логики с помощью интерфейса вызова с аргументами.

   [[./img/function.svg]]

   Эффект функции на состояние системы это возвращаемое значение и побочные эффекты; удобнее, когда эффектов нет или минимальное количество.
   Подпрограммы следуют этой схеме, однако при несоблюдении соглашения вызова подпрограмма может испортить состояние вызывающей её функции. Это происходит когда функция не восстанавливает caller-saved регистры (например, =rsp=), или когда вызывающая функция не сохраняет нужные регистры перед вызовом (см.  пример  c вызовом =string_length=).
   # ]

   # <
   [[./img/function.svg]]
   - Functions abstract their execution through interface (calling with arguments).

   - Calling subroutine looks like calling functions...

     ... but is able to corrupt the state of the calling subroutine.

   # >
   -----
    

   - Typical scenario I:
     - Subroutine works as expected.
     - Different part of program crashes.
   - Typical scenario II:
     - Subroutine works as expected.
     - In future we modify a different module.
     - Different part of program crashes.

     # [
     Если воспринимать подпрограммы или функции как модули, то несоблюдение соглашений вызова ведёт к ошибкам, распространяющимся по системе от модуля к модулю. В системах это один из наиболее тяжёлых для диагностики типов ошибок.
     В высокоуровневых многопоточных приложениях в индустрии такие ошибки порой ищутся *месяцами*.,
     # ]
     -----
* Weak & Enforced modularity

  # [
  Как мы увидели,  набор модулей-подпрограмм это очень хрупкая конструкция. Ошибки могут свободно распространяться между модулями; лёгкий способ этого достичь это не следовать соглашению вызова.
  # ]
  
  Модули-подпрограммы это пример /слабой модульности/ (weak modularity), не мешающей распространяться ошибкам по системе.
  
  /Сильная модульность/ (enforced modularity) ставит барьеры на пути распространения ошибок.

  Усилить модульность в системе можно с помощью /клиент-сервисной архитектуры/ и/или /виртуализации/.

  -----

   # [
   Пока мы рассматривали ситуацию с запуском одного приложения. Однако в реальности мы хотим, чтобы на компьютере одновременно выполнялось множество программ! Поскольку память в компьютере одна, оказывается, что из-за слабой модульности ошибки могут не только распространяться между процедурами, но и между приложениями. Любая программа может внести ошибку в работу любой другой --- это очень ненадёжная система.

   # ]
   
   # < 
   - Если процессы делят общую память и процессор, то могут свободно обмениваться данными и повреждать друг друга.
   # >
   
   [[./img/von-neumann-complete.svg]]

   # <
   - Процессы можно считать модулями в вычислительной системе.
   - Ошибка в модуле ведёт к падению всей системы --- *это слабая модульность*.
   #  >
   
   # [
   На более примитивных системах типичной была ситуация, когда все процессы
   жили в одном адресном пространстве, без виртуальной памяти.
   # ]
   
   -----
# <
   - Модульность можно усиливать с помощью /клиент-сервисной архитектуры/ и /виртуализации/. 
   - В следующей лекции --- как /виртуализировать/ процессор и память.
     # >

   # [
  Существуют два важных архитектурных приёма, укрепляющих границы между модулями в системе. Это клиент-сервисная архитектура и виртуализация функциональных компонентов.

  В следующем разделе мы поговорим про виртуализацию процессора и памяти, позволяющую изолировать процессы друг от друга.
  
   # ]


   

     [[./img/multiple-threads.svg]]


